{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN9OtZGHPQvIglFakcqjcqa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rSFnXGcRWSlA","executionInfo":{"status":"ok","timestamp":1700494167048,"user_tz":-60,"elapsed":18571,"user":{"displayName":"SHAYAN ALVANSAZ","userId":"12478043907558304754"}},"outputId":"27cb0e37-a995-4244-b43f-898e73c6857a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install pandas requests"],"metadata":{"id":"XYIjPpbMWXR9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import json\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define the path to the dataset\n","dataset_path = '/content/drive/MyDrive/archive'\n","\n","# Define the states and their respective cities\n","states_cities = {\n","    \"Florida\": [\"Miami\", \"Orlando\"],\n","    \"California\": [\"Los Angeles\", \"San Francisco\"],\n","    \"New York\": [\"New York\", \"Buffalo\"],\n","    \"Texas\": [\"Houston\", \"Austin\"],\n","    \"Washington\": [\"Seattle\", \"Spokane\"],\n","    \"Maryland\": [\"Baltimore\", \"Silver Spring\"],\n","    \"Arizona\": [\"Phoenix\", \"Tucson\"]\n","}\n","\n","# Function to read and process each CSV file\n","def read_csv(city):\n","    city_formatted = city.replace(\" \", \"\")\n","    file_name = f\"{city_formatted}_Final_2022-06-18.csv\"\n","    file_path = os.path.join(dataset_path, file_name)\n","    try:\n","        df = pd.read_csv(file_path)\n","        return df['scientific_name'].dropna().tolist()\n","    except FileNotFoundError:\n","        return None\n","\n","# Collecting all scientific names from all cities\n","all_scientific_names = {}\n","city_tree_counts = {}  # This will store the tree counts per city\n","\n","for state, cities in states_cities.items():\n","    for city in cities:\n","        names = read_csv(city)\n","        if names:\n","            city_tree_counts[city] = len(names)  # Count the trees for the city\n","            for name in names:\n","                if name in all_scientific_names:\n","                    all_scientific_names[name].add(city)\n","                else:\n","                    all_scientific_names[name] = {city}\n","\n","# Counting the number of cities each scientific name is shared among and selecting the top 15\n","shared_count = {name: len(cities) for name, cities in all_scientific_names.items()}\n","top_shared_names = sorted(shared_count, key=shared_count.get, reverse=True)[:15]\n","\n","# Function to process each city and extract the top shared scientific names with tree counts\n","def process_top_shared_csv(state, city):\n","    city_formatted = city.replace(\" \", \"\")\n","    file_name = f\"{city_formatted}_Final_2022-06-18.csv\"\n","    file_path = os.path.join(dataset_path, file_name)\n","    try:\n","        df = pd.read_csv(file_path)\n","        # Filter for top shared scientific names\n","        city_sci_names = df['scientific_name'].value_counts().to_dict()  # Get counts for each scientific name\n","        scientific_names = [{\n","            \"name\": name,\n","            \"count\": count\n","        } for name, count in city_sci_names.items() if name in top_shared_names]\n","        return {\"name\": city, \"tree_count\": city_tree_counts[city], \"scientific_names\": scientific_names}\n","    except FileNotFoundError:\n","        return None\n","\n","# Process each city in the defined states and create a new structure\n","top_shared_results = []\n","for state, cities in states_cities.items():\n","    city_results = [process_top_shared_csv(state, city) for city in cities if process_top_shared_csv(state, city) is not None]\n","    if city_results:\n","        top_shared_results.append({\"state\": state, \"cities\": city_results})\n","\n","# Save the top shared results to a JSON file in Google Drive\n","json_file_path = '/content/drive/MyDrive/scientific_names_top_shared.json'\n","with open(json_file_path, 'w') as json_file:\n","    json.dump(top_shared_results, json_file)\n","\n","print(f\"JSON file saved to {json_file_path}\")"],"metadata":{"id":"KuJi4DrnWeA_"},"execution_count":null,"outputs":[]}]}